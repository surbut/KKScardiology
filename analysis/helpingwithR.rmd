---
title: "helpingwithR"
author: "Sarah Urbut"
date: "2019-07-16"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Introduction


First, we read in the file and look at its dimensions:
```{r}

data=na.omit(na.omit(data.frame(read.csv("~/desktop/KTS data.csv",header=T))))
dim(data)
```

There are 209 rows and 271 columsn. We can extract the colnames if we're interested and store the first 23 columns as covariates.

```{r}
head(colnames(data))
covariates=data[,1:23]
```




```{r}
model1=lm(formula = data$kccq_score ~ data$FGF21 + data$echo_bmi + data$age + data$diabetes +data$female +data$gfr)
summary(model1)
```


Your questions:
```
^does this mean FGF21 is significantly associated with KCCQ score after accounting for BMI, age, diabetes, sex, and GFR (since p value is 0.047)?
```

Yes, in a strictly frequentist sense if you use the p value to assign significante. You could also examine the 95% confidence interval of the coefficient for FGF21
```{r}
coefficients=model1$coefficients
std.error=coef(summary(model1))[, "Std. Error"]
lowerbound=coefficients[2]+std.error[2]*qnorm(0.025)

upperbound=coefficients[2]+std.error[2]*qnorm(0.975)
```

We see that the 95% confidence interval for this coefficient, `r c(lowerbound,upperbound)` does not cover 0. 

```
^does this mean that age, DM, sex, and GFR are not associated with KCCQ score (p value >0.05 for each)? Or do I need to fit each variable into a separate model and perform ANOVA? similarly, does this means that BMI is associated with KCCQ score (since p value <0.05)?
```

Great questions. Let's break it down. Essnetially the only conclusion we can draw is that in this model (and that's critical, every conclusion applies to a specific model and not a model which might include different or additional covariates) these covariates are not associated according to a frequentist signficance threshold of 0.05. But you might ask in a stepwise fashion what if we exclude one of the covariates,say DM, is age then signficiant? A great example of this is watching how the J shaped curve for composite cardiovascular risk does not change when controlling for race, gender, and DM, but does after controlling for age; at each iteration of the model, a low diastolic blood pressure is singificantly associated with increased CVD risk, but when age is added in, this is no longer true, becuase age better explains the increased risk of death and diastolic blood pressure was probably just a correlated 'marker' that masked underlying risk by age. It's coming out in this week's NEJM, just saw ti in the print edition. To test your question, we can try something simpler than ANOVA (which aims to find the model that best explains the greates proportion of variation while discounting for additional parameters).  WE simply add each covariate in a stepwise fashion. I"ll just do it for 3, using bmi as the baseline covariate, and exclude the intercept term with -1:

```{r}
m1=lm(formula = data$kccq_score ~ data$FGF21 + data$echo_bmi-1)
m2=lm(formula = data$kccq_score ~ data$FGF21 + data$echo_bmi+ data$age-1)
m3=lm(formula = data$kccq_score ~ data$FGF21 + data$echo_bmi+ data$age+data$diabetes-1)

summary(m1)
summary(m2)
summary(m3)
```

Interestingly, FGF21 is signficiatnly associated with kccq score when controlling for only BMI, but not when controlling for age, meaning that a good proportion of the variation in kccq score that is explained by FGF21 levels is better explained by age.


```
^do I need to correct for doing multiple comparisons (eg, false discovery rate)?
```

You only correct for FDR when asking multiple questions about associated variables (and not adjusted variables, though this is somewhat of an arbitrary distinction). So for example, if we adjusted for age, gender, race and bmim, and then asked if 20 of your metabolites were associated with kccq score, we would need to report a q value of local false discovery rate or (sign) a naiive bonferroni adjustment, but this is usually done with testing each metablite separately rather than in a model that controls for all simultaneously. So traditional analsysi would probably fit  data$kccq_score ~ data$FGF21 + data$echo_bmi + data$age + metab1 and then  data$kccq_score ~ data$FGF21 + data$echo_bmi + data$age + metabolite2 etc., and then correct the reported coefficients in each model when reporting  a list of many metabolites. Does that make sense?
  
  
```
how can I plot FGF21 over KCCQ score after adjusting for BMI, age, diabetes, sex, and GFR? When I use the plot function, it plots GFR over KCCQ score
```

I'm not exactly sure qhat you're asking, but what I think you want is the model fit for predicted kccq score over the initial FGF21.

```{r}
plot(data$FGF21,model1$fitted.values,xlab="FGF21",ylab="KCCQscore",pch=2,col="red",lwd=2)
points(data$FGF21,data$kccq_score,col="blue",pch=1)
legend(2,60,c("fittedvalues","originalvalues"),pch=c(2,1),col=c("red","blue"))
```

```{
this doesn't seem correct. The Asian group is missing. How can I code Asian, Black, and White as separate groups (eg, 1, 2, 3). Again, I think I need to account for multiple comparisons using FDR or Bonferroni. Ultimately, I would ideally like to account for race in model 1 for to see if it affects KCCQ score on FGF21
```

The best way is to examine the model matrix and see how the linear algebra is done. It looks like asian is treated as the intercept case, and then black and white are added to this. So, a white individual's kccq score would be the intercept term + white coefficient, and a black individual would be the intercept + -1.24, and asian would be just the intercet. I've shown you the predictions for a sample white, black and asian individual.
```{r}
model2=lm(data$FGF21 ~data$race)
head(model.matrix(model2))

predict(model2)[which(data$race=="white")[1]]
predict(model2)[which(data$race=="black")[1]]
predict(model2)[which(data$race=="asian")[1]]

```

If you want to avoid an intercept, simply subtract 1 fromn the design matrix. YOu see that now everyone just has an indicator variable for their race.

```{r}
model2=lm(data$FGF21 ~data$race-1)
head(model.matrix(model2))
boxplot(data$FGF21 ~data$race-1)
```

Here you do NOT need to control for multiple comparisons because you are really just doing a 1 factor (3 level) ANOVA: there is just one variable with three different levels. I hope this helps, and PLEASE let me know if I can help. SO glad you like R!

